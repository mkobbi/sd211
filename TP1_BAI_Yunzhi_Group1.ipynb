{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TP : SYSTEMES DE RECOMMANDATION \n",
    "\n",
    "**Nom et Prénom:**   BAI Yunzhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Présentation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** Ici, j'ai fait des copies des fonctions fournis (déjà complétés par moi-même). C'est pour les lire et utiliser plus facile. Merci de ne pas supprimer cette partie (ni import movielensutils). Sinon, ce programme ne va pas bien marcher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import movielensutils\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "def load_movielens(filename, minidata=False):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename de la base de donnees\n",
    "    Movielens, par exemple \n",
    "    filename = '~/datasets/ml-100k/u.data'\n",
    "    Elle retourne \n",
    "    R : une matrice utilisateur-item contenant les scores\n",
    "    mask : une matrice valant 1 si il y a un score et 0 sinon\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, dtype=int)\n",
    "\n",
    "    R = sparse.coo_matrix((data[:, 2], (data[:, 0]-1, data[:, 1]-1)),\n",
    "                          dtype=float)\n",
    "    R = R.toarray()  # not optimized for big data\n",
    "\n",
    "    # code la fonction 1_K\n",
    "    mask = sparse.coo_matrix((np.ones(data[:, 2].shape),\n",
    "                              (data[:, 0]-1, data[:, 1]-1)), dtype=bool )\n",
    "    mask = mask.toarray()  # not optimized for big data\n",
    "\n",
    "    if minidata is True:\n",
    "        R = R[0:100, 0:200].copy()\n",
    "        mask = mask[0:100, 0:200].copy()\n",
    "\n",
    "    return R, mask\n",
    "\n",
    "\n",
    "def objective(P, Q0, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme simplifie.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q0 : une matrice de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q0.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "    \n",
    "    grad_P = rho* P - (Q0.T).dot(tmp)\n",
    "\n",
    "    return val, grad_P\n",
    "\n",
    "\n",
    "def total_objective(P, Q, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme complet.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    grad_Q : le gradient par rapport a Q\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = rho* P - (Q.T).dot(tmp)\n",
    "\n",
    "    grad_Q = rho* Q - (tmp).dot(P.T)\n",
    "\n",
    "    return val, grad_P, grad_Q\n",
    "\n",
    "\n",
    "def total_objective_vectorized(PQvec, R, mask, rho):\n",
    "    \"\"\"\n",
    "    Vectorisation de la fonction precedente de maniere a ne pas\n",
    "    recoder la fonction gradient\n",
    "    \"\"\"\n",
    "\n",
    "    # reconstruction de P et Q\n",
    "    n_items = R.shape[1]\n",
    "    n_users = R.shape[0]\n",
    "    F = PQvec.shape[0] / (n_items + n_users)\n",
    "    Pvec = PQvec[0:n_items*F]\n",
    "    Qvec = PQvec[n_items*F:]\n",
    "    P = np.reshape(Pvec, (F, n_items))\n",
    "    Q = np.reshape(Qvec, (n_users, F))\n",
    "\n",
    "    val, grad_P, grad_Q = total_objective(P, Q, R, mask, rho)\n",
    "    return val, np.concatenate([grad_P.ravel(), grad_Q.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R, mask = movielensutils.load_movielens('ml-100k/u.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1682) (943, 1682)\n"
     ]
    }
   ],
   "source": [
    "print R.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 200) (100, 200)\n"
     ]
    }
   ],
   "source": [
    "R_mini, mask_mini=movielensutils.load_movielens('ml-100k/u.data',minidata=True)\n",
    "print R_mini.shape, mask_mini.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** On a bien vérifié que les tailles de R et mask sont bien (943,1682). Et l'option \"minidata\" est juste pour générer les données de tailles réduits, et la taille est (100,200). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as NL\n",
    "mask01=np.ones([943,1682])[mask]\n",
    "nombreTotaleDeNotes=NL.norm(mask01)**2\n",
    "print nombreTotaleDeNotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** \n",
    "1. Il y a 943 utilisateurs.\n",
    "2. Il y a 1682 films.\n",
    "3. Il y a 100000 notes qui sont donnés par les utilisateurs sur les films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reponses:**\n",
    "1. La fonction objectif n'est pas convexe. On a un contre-exemple pour convexe: on suppose rho=0, P et Q sont de dimension 1; pour r!=1, on a f(r,1)=f(1,r)=0; et f((1+r)/2,(1+r)/2)>0. Donc, on a un contre exemple. Donc, elle n'est pas convexe.\n",
    "\n",
    "2.  tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    grad_P = rho* P - (Q.T).dot(tmp)\n",
    "\n",
    "    grad_Q = rho* Q - (tmp).dot(P.T)\n",
    "    \n",
    "3. Les dérivés des gradients ne sont pas bornés. Donc il n'est pas lipschitzien. Donc, il n'a pas une constante de lipschitzien.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Trouve P quand Q0 est fixé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** Dans la suite, on initialise Q0 et P0 par la méthode decomposition svd. De plus, comme ce que le sujet donne, rho=0.1 et C=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 10) (10, 1682)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "U, s, V = svds(R, k=10)\n",
    "Q0=U[:,0:10]\n",
    "P0=V[0:10,:]\n",
    "print Q0.shape, P0.shape\n",
    "\n",
    "rho=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reponses:**\n",
    "1. La fonction n'est pas convexe. Suppose que Q0 est assez petit devant P1 et P2(on peut supposer Q0=>0 pour simplifier), avec P1 et P2 les deux points qu'on choit, on peut trouver facilement que la fonction n'est pas convexe.\n",
    "\n",
    "2.  tmp = (R - Q0.dot(P)) * mask\n",
    "\n",
    "    grad_P = rho* P - (Q0.T).dot(tmp)\n",
    "\n",
    "3. La dérivés du gradient est bornée maintenant. On peut obtenir une constante de lipschitzien = rho+NL.norm((Q0.T).dot(Q0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La taille du grad_P:(10, 1682)\n",
      "La norme du grad_P:799.115664685\n",
      "1.47903090092\n"
     ]
    }
   ],
   "source": [
    "#Q est matrix de utilisateur, P est matrix de items.\n",
    "#Q(u,c) u=943; P(c,i), I=1682\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "def func(P):\n",
    "    P=np.reshape(P,(10,1682))\n",
    "    tmp = (R - Q0.dot(P))*mask\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "    return val\n",
    "\n",
    "def grad(P):\n",
    "    P=np.reshape(P,(10,1682))\n",
    "    tmp = (R - Q0.dot(P))*mask\n",
    "    grad_P = rho * P - (Q0.T).dot(tmp)\n",
    "    print(\"La taille du grad_P:\"+str(grad_P.shape))\n",
    "    print(\"La norme du grad_P:\"+str(NL.norm(grad_P)))\n",
    "    return grad_P.ravel()\n",
    "\n",
    "\n",
    "print check_grad(func, grad, P0.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Remarques:** On voit que la différence est environ 1.46. Comme grad_P est de taille (10,1682), et la valeur du grad_p est presque 800 qui est beaucoup plus grande que 1.46 , cette différence est négligéable. Donc, ici on peut dire notre exprission du gradient est correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Remarques:**\n",
    "Ici, j'introduit un nouveau paramètre \"nombreIteration\" afin d'ajouter une autre type de critère de conditions d'arrêt. C'est pour évider que l'algorithme déroule pendant trop de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gradient(g, P0, gamma, epsilon, nombreIteration=False):\n",
    "    if nombreIteration==False :\n",
    "        P=P0\n",
    "        val, grad=g(P)\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon:\n",
    "                return val, P, nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                P=P-gamma*grad\n",
    "                val, grad=g(P)\n",
    "    else:          \n",
    "        P=P0\n",
    "        val, grad=g(P)\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon or nombre>=nombreIteration:\n",
    "                return val, P, nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                P=P-gamma*grad\n",
    "                val, grad=g(P)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 1e-05\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 0.0001\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 0.001\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 0.01\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 0.1\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 1.0\n",
      "valeur optimale: 684334.098444    nombre d'itération: 0    gamma: 10.0\n"
     ]
    }
   ],
   "source": [
    "epsilon=1.\n",
    "for gamma in np.logspace(-5,1,7):\n",
    "    val,P_,nombre=gradient(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma,epsilon=epsilon,nombreIteration=500)\n",
    "    print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre)+\"    gamma: \"+str(gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** On trouve que les meilleur gammas sont 0.01, 0.1, 1. Donc, on peut choisir un des trois valeurs. De plus, on peut voir que si le pas est trop petit, la vitesse de convergence est très lente. Si le pas est trop grand, on ne peut pas faire fonctionner notre algorithme correctement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensuite**, on utilise 1/L0 pour le pas, avec L0 le constant lipschitzien pour Q0 fixé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma utilisé:0.306534300317\n",
      "valeur optimale: 215965.602538    nombre d'itération: 90\n"
     ]
    }
   ],
   "source": [
    "epsilon=1.\n",
    "constantLipschitzien=rho+NL.norm((Q0.T).dot(Q0))\n",
    "gamma_donne=1./constantLipschitzien\n",
    "print(\"gamma utilisé:\"+str(gamma_donne))\n",
    "val,P_,nombre=gradient(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma_donne,epsilon=epsilon,nombreIteration=500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Raffinements algorithmiques pour le problème à Q0 fixé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE:** Ici, on utilise \"Line Search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def objectiveGamma(gamma,X0,direction,f):\n",
    "    X=X0 + gamma*direction\n",
    "    val, grad_0 = f(X)\n",
    "    \n",
    "    return val\n",
    "\n",
    "\n",
    "def gradient_LinearSearch(g, pointDepart, epsilon, nombreIteration=False):\n",
    "    if nombreIteration==False :\n",
    "        pointCourant=pointDepart\n",
    "        val, grad=g(pointCourant)\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon:\n",
    "                return val,pointCourant,nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                direction=-grad\n",
    "                gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "                pointCourant=pointCourant+gamma*direction\n",
    "                val, grad=g(pointCourant)\n",
    "    else:          \n",
    "        pointCourant=pointDepart\n",
    "        val, grad=g(pointCourant)\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon or nombre>=nombreIteration:\n",
    "                return val, pointCourant,nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                direction=-grad\n",
    "                gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "                pointCourant=pointCourant+gamma*direction\n",
    "                val, grad=g(pointCourant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 215963.767755    nombre d'itération: 17\n"
     ]
    }
   ],
   "source": [
    "val,P_optimal,nombre=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon,nombreIteration=500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** Ici, on utilise la méthode \"gradient conjugé pour une fonction quelconque\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_Conjuge(g, pointDepart, epsilon, nombreIteration=False):\n",
    "    if nombreIteration==False :\n",
    "        pointCourant=pointDepart\n",
    "        val, grad=g(pointCourant)\n",
    "        direction=-grad\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon:\n",
    "                return val, pointCourant, nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "                pointCourant=pointCourant+gamma*direction\n",
    "                norm1=NL.norm(grad)**2\n",
    "                val, grad=g(pointCourant)\n",
    "                norm2=NL.norm(grad)**2\n",
    "                b=norm2/norm1\n",
    "                direction=-grad+b*direction\n",
    "    else:          \n",
    "        pointCourant=pointDepart\n",
    "        val, grad=g(pointCourant)\n",
    "        direction=-grad\n",
    "        nombre=0\n",
    "        while(True):\n",
    "            if NL.norm(grad)<=epsilon or nombre>=nombreIteration:\n",
    "                return val, pointCourant, nombre\n",
    "            else:\n",
    "                nombre=nombre+1\n",
    "                gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "                pointCourant=pointCourant+gamma*direction\n",
    "                norm1=NL.norm(grad)**2\n",
    "                val, grad=g(pointCourant)\n",
    "                norm2=NL.norm(grad)**2\n",
    "                b=norm2/norm1\n",
    "                direction=-grad+b*direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 215963.131801    nombre d'itération: 9\n"
     ]
    }
   ],
   "source": [
    "val,P_optimal,nombre=gradient_Conjuge(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon,nombreIteration=500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with constant step size:\n",
      "value_optimal:215965.602538\n",
      "nombreIteration:90\n",
      "run time:3.31\n",
      "\n",
      "Gradient with line search:\n",
      "value_optimal:215963.767755\n",
      "nombreIteration:17\n",
      "run time:12.08\n",
      "\n",
      "Gradient conjugé:\n",
      "value_optimal:215963.131801\n",
      "nombreIteration:9\n",
      "run time:5.27\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.clock()\n",
    "\n",
    "print \"Gradient with constant step size:\"\n",
    "t1=time.clock()\n",
    "val,P_,nombre=gradient(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma_donne,epsilon=epsilon,nombreIteration=500)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n",
    "print(\"\")\n",
    "print \"Gradient with line search:\"\n",
    "t1=time.clock()\n",
    "val,P_optimal,nombre=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon,nombreIteration=500)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n",
    "print(\"\")\n",
    "print \"Gradient conjugé:\"\n",
    "t1=time.clock()\n",
    "val,P_optimal,nombre=gradient_Conjuge(g=lambda P:movielensutils.objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon,nombreIteration=500)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Remarques:**\n",
    "1. On trouve que tous les trois algorithmes peuvent atteindre la valeur optimale, mais avec le temps du calcul et le nombre d'itération différentes.\n",
    "2. Il y a pas beaucoup de différences entre les valeurs optimales obtenues. Mais on peut trouver que \"Line Searche\" et \"gradient conjugé\" sont un peu mieux que \"gradient with constant step\".\n",
    "3. Pour le temps du calcul, \"gradient constant step\" est plus rapide que \"gradient conjugé\", et \"gradient conjugé\" est plus rapide que \"line search\". Mais en fait, pour \"gradient constant step\", on doit passer pas mal de temps pour chercher le constant de lipschitzien. Donc, pour le temps du calcul total, \"gradient constant step\" ne vais pas donner un mieux résultat que les autres.\n",
    "4. Pour la vitesse de convergence, \"gradient conjugé\" est mieux que \"line search\", et les deux premiers sont beaucoup mieux que \"gradient constant step\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Résolution du problème complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 25633.2541509    nombre d'itération: 500\n"
     ]
    }
   ],
   "source": [
    "PQ0=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val, PQ, nombre = gradient_LinearSearch(lambda PQvec:total_objective_vectorized(PQvec, R=R, mask=mask, rho=rho),pointDepart=PQ0,epsilon=epsilon,nombreIteration=500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 24843.9936788    nombre d'itération: 1000\n"
     ]
    }
   ],
   "source": [
    "PQ0=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val, PQ, nombre = gradient_LinearSearch(lambda PQvec:total_objective_vectorized(PQvec, R=R, mask=mask, rho=rho),pointDepart=PQ0,epsilon=epsilon,nombreIteration=1000)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 24542.7814544    nombre d'itération: 1500\n"
     ]
    }
   ],
   "source": [
    "PQ0=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val, PQ, nombre = gradient_LinearSearch(lambda PQvec:total_objective_vectorized(PQvec, R=R, mask=mask, rho=rho),pointDepart=PQ0,epsilon=epsilon,nombreIteration=1500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:**\n",
    "1. L'algorithme va renvoyer une valeur optimal, un vecteur PQ, et un nombre d'itération. Ici, le vecteur PQ est un vecteur de taille (9430+16820)=(26250), où les composants sont les valeurs de P et puis Q. Donc, pour avoir Q.dot(P), il faut reconstruire les matrices P et Q à partir ce vecteur PQ.\n",
    "2. La vitesse de convergence n'est pas vite. Mais on peut sentir que la valeur optimale n'est pas loin que 24542.(pour nombre d'itération=5000, on a 24017)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reponses:**\n",
    "1. On peut savoir que f(P1,Q0) <= f(P0,Q0), parce que quand Q=Q0, P1 minimise la valeur du f parmi les autres P. Même raisonnemnt, f(P1,Q1) <= f(P1,Q0), parce que Q1 minimise f quand P=P1. Ainsi, f(P2,Q1) <= f(P1,Q1)... Donc, par récurrence, on peut savoir que f décroit à chaque itération.\n",
    "2. Comme f décroit à chaque itération et on a un valeur minimal du f, donc elle converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUES:** \n",
    "1. Ici, j'utilise un critère d'un condition d'arrêt différent que les autres algorithmes. Je calcul la différrence des valeurs obtenus par deux successives appels de \"gradient_LinearSearch à Q ou P fixé\". Si la différence est inférieur à epsilon, on sort. (on peut aussi vérifier que les deux gradients obténus sont tous inférieurs à epsilon).\n",
    "2. De plus, je compte le nombre d'itération total. Je mets à jour ce nombre après chaque appel de \"gradient_LinearSearch\": j'ajoute à ce nombre par le nombre d'itération utilisé dans cet appel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_Q(Q, P0, R, mask, rho):\n",
    "    val, grad_P, grad_Q=total_objective(P=P0,Q=Q,R=R,mask=mask,rho=rho)\n",
    "    return val, grad_Q\n",
    "\n",
    "\n",
    "\n",
    "def gradient_MoindreCarre(P0,Q0,R,mask,rho,epsilon, nombreIteration=False):\n",
    "    if nombreIteration==False :\n",
    "        \n",
    "        nombre=0\n",
    "        val_avant=0\n",
    "        P_courant=P0\n",
    "        Q_courant=Q0\n",
    "        \n",
    "        val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon,nombreIteration=500)\n",
    "        nombre=nombre+nbr\n",
    "        P_courant=P_optimal\n",
    "        \n",
    "        val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon,nombreIteration=500)\n",
    "        nombre=nombre+nbr\n",
    "        Q_courant=Q_optimal\n",
    "        \n",
    "        difference=np.abs(val1-val2)\n",
    "        \n",
    "        while(True):\n",
    "            if difference<=epsilon :\n",
    "                return val2,P_courant,Q_courant,nombre\n",
    "            else:\n",
    "                val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon,nombreIteration=500)\n",
    "                nombre=nombre+nbr\n",
    "                P_courant=P_optimal\n",
    "\n",
    "                val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon,nombreIteration=500)\n",
    "                nombre=nombre+nbr\n",
    "                Q_courant=Q_optimal\n",
    "\n",
    "                difference=np.abs(val1-val2)\n",
    "                \n",
    "\n",
    "    else:          \n",
    "        nombre=0\n",
    "        val_avant=0\n",
    "        P_courant=P0\n",
    "        Q_courant=Q0\n",
    "        \n",
    "        val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon,nombreIteration=500)\n",
    "        nombre=nombre+nbr\n",
    "        P_courant=P_optimal\n",
    "        \n",
    "        val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon,nombreIteration=500)\n",
    "        nombre=nombre+nbr\n",
    "        Q_courant=Q_optimal\n",
    "        \n",
    "        difference=np.abs(val1-val2)\n",
    "        \n",
    "        while(True):\n",
    "            if difference<=epsilon or nombre >= nombreIteration:\n",
    "                return val2,P_courant,Q_courant,nombre\n",
    "            else:\n",
    "                val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:movielensutils.objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon,nombreIteration=500)\n",
    "                nombre=nombre+nbr\n",
    "                P_courant=P_optimal\n",
    "\n",
    "                val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon,nombreIteration=500)\n",
    "                nombre=nombre+nbr\n",
    "                Q_courant=Q_optimal\n",
    "\n",
    "                difference=np.abs(val1-val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 129579.562278    nombre d'itération: 509\n"
     ]
    }
   ],
   "source": [
    "val, P, Q, nombre=gradient_MoindreCarre(P0=P0,Q0=Q0,R=R,mask=mask,rho=rho,epsilon=10., nombreIteration=500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 70642.6342025    nombre d'itération: 1097\n"
     ]
    }
   ],
   "source": [
    "val, P, Q, nombre=gradient_MoindreCarre(P0=P0,Q0=Q0,R=R,mask=mask,rho=rho,epsilon=10., nombreIteration=1000)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 53357.4072155    nombre d'itération: 1719\n"
     ]
    }
   ],
   "source": [
    "val, P, Q, nombre=gradient_MoindreCarre(P0=P0,Q0=Q0,R=R,mask=mask,rho=rho,epsilon=10., nombreIteration=1500)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarque:** Il converge un peu lentement en considérant le nombre d'itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 37494.6342925    nombre d'itération: 5505\n"
     ]
    }
   ],
   "source": [
    "val, P, Q, nombre=gradient_MoindreCarre(P0=P0,Q0=Q0,R=R,mask=mask,rho=rho,epsilon=10., nombreIteration=5000)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 24017.3159679    nombre d'itération: 5000\n"
     ]
    }
   ],
   "source": [
    "PQ0=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val, PQ, nombre = gradient_LinearSearch(lambda PQvec:total_objective_vectorized(PQvec, R=R, mask=mask, rho=rho),pointDepart=PQ0,epsilon=epsilon,nombreIteration=5000)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** On peut voir que la méthode de moindre carré alterné converge plus lentement que gradient avec recherche linéaire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remarques:** Comme le sujet a déjà fourni la valeur du rho, je suppose que l'on n'a pas besoin de varier cette valeur pour trouver une meilleur valeur optimale du fonction. C'est à dire, on n'a pas besoin de faire (juste pour montrer ce que on doit faire si le sujet ne donne pas la valeur du rho):\n",
    "1. Séparer les données en deux parties, un pour apprentissage, un pour validation(chercher rho).\n",
    "2. Pour un rho choisi, faire apprentissage et puis le test par norm(R-QP) en utilisant les données de validation. On va obtenir une valeur d'erreur( norm(R-QP) en les données de validation ).\n",
    "3. On fait 3 avec des rhos différents et choisit un rho qui a une valeur d'erreur minimale.\n",
    "4. On utilise ce rho pour prédire, c'est à dire prédire les notes des films qui ne sont pas données par un utilisateur choisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_items = R.shape[1]\n",
    "n_users = R.shape[0]\n",
    "F = PQ.shape[0] / (n_items + n_users)\n",
    "Pvec = PQ[0:n_items*F]\n",
    "Qvec = PQ[n_items*F:]\n",
    "P = np.reshape(Pvec, (F, n_items))\n",
    "Q = np.reshape(Qvec, (n_users, F))\n",
    "\n",
    "result=Q.dot(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.25507499  3.5448692   3.42647779 ...,  0.36835218  2.50951649\n",
      "  2.7764629 ]\n"
     ]
    }
   ],
   "source": [
    "print result[449]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On cherche les fillms qui ont notes supérieurs à 4.5 et qui n'avait pas un note avant, pour utilisateur 449.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[235, 245, 250, 255, 336, 407, 463, 514, 530, 675, 732, 908, 954, 957, 962, 1004, 1005, 1063, 1130, 1133, 1165, 1166, 1168, 1175, 1188, 1193, 1194, 1216, 1232, 1250, 1277, 1280, 1393, 1397, 1425, 1430, 1448, 1450, 1462, 1473, 1515, 1530, 1588, 1593, 1641, 1642]\n",
      "[4.5605072765180674, 4.6225599970884366, 4.5250448757269703, 4.6308181407912805, 4.7459618283566307, 4.82981727158817, 5.1520874643615571, 4.6171470144388485, 4.5105559246866935, 4.8552461834053675, 4.5398405330586131, 4.5164215438324762, 5.2338648995518664, 4.6659272667826475, 5.1847780908789032, 5.1760353245053476, 4.7030326223363863, 4.6823211656564521, 4.5740756996151157, 4.7046132080138303, 4.8680789952428469, 4.7881642845548651, 4.71852110755857, 4.7288868633186674, 4.9010945205290852, 4.7241627231127366, 4.5286585668569828, 4.6926540183137693, 4.9154498616382689, 5.1683873009780452, 4.6445100231548357, 4.502034452088683, 4.6447272803557826, 4.5298912493782915, 4.549042073716814, 4.7089980292570548, 4.8369742907468352, 4.6054759878757734, 4.8663456287523426, 4.5245508802947363, 4.8093277549765778, 4.6882351628409893, 5.1133796790038497, 4.517769267391607, 4.5539018896766317, 5.4325789327295793]\n"
     ]
    }
   ],
   "source": [
    "films_recommande=[]\n",
    "notess=[]\n",
    "for i in np.arange(n_items):\n",
    "    if R[449][i]==0 and result[449][i]>=4.5:\n",
    "        films_recommande.append(i)\n",
    "        notess.append(result[449][i])\n",
    "\n",
    "print films_recommande\n",
    "print notess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On affiche le film qui a le note le plus grand.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film à recommender: 1642\n",
      "avec notes: 5.43257893273\n"
     ]
    }
   ],
   "source": [
    "max_value = max(notess)\n",
    "max_index = notess.index(max_value)\n",
    "film_best=films_recommande[max_index]\n",
    "print(\"film à recommender: \"+str(film_best))\n",
    "print(\"avec notes: \"+str(max_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
