{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Présentation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from movielensutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R, mask = load_movielens(\"ml-100k/u.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Shape of R: ', (943, 1682))\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of R: \", R.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice retrounée a bien la taille 943 x 1682.\n",
    "L'option minidata permet de récupérer une sous-matrice de R de taille 100 x 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y 943 utilisateurs et 1682 films référencés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of non-zeros', 100000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of non-zeros\", np.count_nonzero(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Pour $Q\\in\\mathcal{M_{\\left|\\mathrm{U}\\right|\\times\\left|\\mathrm{C}\\right|}},$$P\\in\\mathcal{M_{\\left|\\mathrm{C}\\right|\\times\\left|\\mathrm{I}\\right|}}$,\n",
    "on a :\n",
    "\n",
    "\\[\n",
    "\\begin{array}{ccc}\n",
    "f:(P,Q) & \\mapsto & \\frac{1}{2}{\\displaystyle \\sum_{(u,i)\\in K}\\left(r_{ui}-{\\displaystyle \\sum_{c\\in C}q_{uc}p_{ci}}\\right)^{2}+\\frac{\\rho}{2}\\left(\\sum_{u\\in U,c\\in C}q_{uc}^{2}+\\sum_{c\\in C,i\\in I}p_{ci}^{2}\\right)}\\\\\n",
    " & = & \\frac{1}{2}{\\displaystyle \\sum_{(u,i)\\in K}\\sum_{c\\in C}\\left(\\frac{r_{ui}}{\\left|\\mathrm{C}\\right|}-{\\displaystyle q_{uc}p_{ci}}\\right)^{2}+\\frac{\\rho}{2}\\left(\\sum_{u\\in U,c\\in C}q_{uc}^{2}+\\sum_{c\\in C,i\\in I}p_{ci}^{2}\\right)}\\\\\n",
    " & = & \\frac{1}{2}{\\displaystyle \\sum_{(u,i)\\in K}\\sum_{c\\in C}\\left(\\frac{r_{ui}}{\\left|\\mathrm{C}\\right|}^{2}-{\\displaystyle 2\\frac{r_{ui}}{\\left|\\mathrm{C}\\right|}q_{uc}p_{ci}+\\left(q_{uc}p_{ci}\\right)^{2}}\\right)+\\frac{\\rho}{2}\\left(\\sum_{u\\in U,c\\in C}q_{uc}^{2}+\\sum_{c\\in C,i\\in I}p_{ci}^{2}\\right)}\\\\\n",
    " & = & {\\displaystyle \\sum_{u\\in U}\\sum_{i\\in I}\\sum_{c\\in C}\\left(\\frac{r_{ui}}{2\\left|\\mathrm{C}\\right|}^{2}-{\\displaystyle \\frac{r_{ui}}{\\left|\\mathrm{C}\\right|}q_{uc}p_{ci}}+\\frac{\\rho}{2}q_{uc}^{2}+\\frac{\\rho}{2}p_{ci}^{2}\\right)}+{\\displaystyle \\sum_{u\\in U}}{\\displaystyle \\sum_{i\\in I}}{\\displaystyle \\sum_{c\\in C}}\\frac{1}{2}\\left(q_{uc}p_{ci}\\right)^{2}\\\\\n",
    " & = & {\\displaystyle \\sum_{u\\in U}\\sum_{i\\in I}\\sum_{c\\in C}}\\left(g\\left(q_{uc},p_{ci}\\right)+\\frac{1}{2}h\\left(q_{uc},p_{ci}\\right)\\right)\n",
    "\\end{array}\n",
    "\\]\n",
    "\n",
    "\n",
    "où $g$ est une forme quadratique sur $\\mathbb{R}^{2}$et $h:(x,y)\\mapsto(xy)^{2}$\n",
    "\n",
    "Pour $\\overrightarrow{u}=(1,0),\\overrightarrow{v}=(0,1),t=\\frac{1}{2}$,\n",
    "on a :\n",
    "\n",
    "\\begin{equation}\n",
    "h\\left(t\\overrightarrow{u}+\\left(1-t\\right)\\overrightarrow{v}\\right)>th\\left(\\overrightarrow{u}\\right)+\\left(1-t\\right)h\\left(\\overrightarrow{v}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "$h$ est donc non convexe.\n",
    "\n",
    "Par suite, $f$ est non convexe.\n",
    "Pour $Q\\in\\mathcal{M_{\\left|\\mathrm{U}\\right|\\times\\left|\\mathrm{C}\\right|}},$$P\\in\\mathcal{M_{\\left|\\mathrm{C}\\right|\\times\\left|\\mathrm{I}\\right|}}$,\n",
    "on a :\n",
    "\\begin{equation}\n",
    "\\overrightarrow{grad}f\\left(P,Q\\right)=\\left(\\begin{array}{c}\n",
    "\\frac{\\partial f(P,Q)}{\\partial P}\\\\\n",
    "\\frac{\\partial f(P,Q)}{\\partial Q}\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "et\n",
    "\n",
    "\\begin{equation}\n",
    "f\\left(P,Q\\right)=\\frac{1}{2}\\left\\Vert 1_{K}\\circ\\left(R-QP\\right)\\right\\Vert _{F}^{2}+\\frac{\\rho}{2}\\left(\\left\\Vert Q\\right\\Vert _{F}^{2}+\\left\\Vert P\\right\\Vert _{F}^{2}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "On pose\n",
    "\n",
    "\\begin{equation}\n",
    "\\delta:(P,Q)\\mapsto\\left\\Vert 1_{K}\\circ\\left(R-QP\\right)\\right\\Vert _{F}^{2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "et \n",
    "\\begin{equation}\n",
    "M=1_{K}\\circ\\left(R-QP\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "On obtient :\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{ccc}\n",
    "\\partial M & = & \\partial\\left(1_{K}\\circ\\left(R-QP\\right)\\right)\\\\\n",
    " & = & \\left(\\partial1_{K}\\right)\\circ\\left(R-QP\\right)+1_{K}\\circ\\partial\\left(R-QP\\right)\\\\\n",
    " & = & 1_{K}\\circ\\left(\\partial R-\\partial\\left(QP\\right)\\right)\\\\\n",
    " & = & -1_{K}\\circ\\left(\\left(\\partial Q\\right)P+Q\\left(\\partial P\\right)\\right)\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "D'où \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{ccc}\n",
    "\\frac{\\partial f(P,Q)}{\\partial P} & = & 2\\left\\langle M,\\frac{\\partial M}{\\partial P}\\right\\rangle +\\rho P\\\\\n",
    " & = & -Q^{t}\\times1_{K}\\circ\\left(R-QP\\right)+\\rho P\\\\\n",
    "\\frac{\\partial f(P,Q)}{\\partial Q} & = & -1_{K}\\circ\\left(R-QP\\right)\\times P^{t}+\\rho Q\n",
    "\\end{array}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Les différentielles du gradient ne sont pas bornées. Donc il n'est\n",
    "pas Lipschitzien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Trouver $P$ lorsque $Q_{0}$ est fixé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 6) (6, 1682)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "C=6 #{0,...,6}\n",
    "U, s, V = svds(R, k=C)\n",
    "Q0=U[:,0:C]\n",
    "P0=V[0:C,:]\n",
    "print Q0.shape, P0.shape\n",
    "\n",
    "rho=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $Q_{0}$ fixé, on a :\n",
    "\\begin{array}{ccc}\n",
    "f(P,Q_{0}) & = & {\\displaystyle \\sum_{u\\in U}\\sum_{i\\in I}\\sum_{c\\in C}\\left(\\frac{r_{ui}}{2\\left|\\mathrm{C}\\right|}^{2}-{\\displaystyle \\frac{r_{ui}}{\\left|\\mathrm{C}\\right|}q_{0uc}p_{ci}}+\\frac{\\rho}{2}q_{0uc}^{2}+\\frac{\\rho}{2}p_{ci}^{2}+\\frac{1}{2}\\left(q_{0uc}p_{ci}\\right)^{2}\\right)}\\\\\n",
    " & = & {\\displaystyle \\sum_{u\\in U}\\sum_{i\\in I}\\sum_{c\\in C}}\\gamma_{u,i,c}\\left(p_{ci}\\right)\n",
    "\\end{array}\n",
    " \n",
    "\n",
    "avec $\\gamma_{u,i,c}$\n",
    "  forme quadratique sur $\\mathbb{R}$\n",
    "  de coefficient de plus haut degré positif. Il s'agit donc d'une forme convexe. D'où $f$\n",
    "  est convexe.\n",
    "\n",
    "Le gradient de f\n",
    "  est \n",
    "\n",
    "$$\\frac{\\partial f(P,Q_0)}{\\partial P}=-Q_0^{t}\\times1_{K}\\circ\\left(R-Q_0P\\right)+\\rho P$$\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-26b4a490d4b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_P\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mcheck_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/cal/softs/anaconda/anaconda-2.0.1/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mcheck_grad\u001b[1;34m(func, grad, x0, *args, **kwargs)\u001b[0m\n\u001b[0;32m    734\u001b[0m         raise ValueError(\"Unknown keyword arguments: %r\" %\n\u001b[0;32m    735\u001b[0m                          (list(kwargs.keys()),))\n\u001b[1;32m--> 736\u001b[1;33m     return sqrt(sum((grad(x0, *args) -\n\u001b[0m\u001b[0;32m    737\u001b[0m                      approx_fprime(x0, func, step, *args))**2))\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import check_grad\n",
    "def objective(P, Q0, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme simplifie.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q0 : une matrice de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q0.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q0 ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = rho*P-(Q0.T).dot(tmp)\n",
    "\n",
    "    return val, grad_P.ravel()\n",
    "\n",
    "val, grad=objective(P0, Q0, R, mask, rho)\n",
    "\n",
    "print check_grad(val,grad, P0.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(g, P0, gamma, epsilon):\n",
    "    P=P0\n",
    "    val, grad=g(P)\n",
    "    nombre=0\n",
    "    while(True):\n",
    "        if np.linalg.norm(grad)<=epsilon:\n",
    "            return val, P, nombre\n",
    "        else:\n",
    "            nombre=nombre+1\n",
    "            P=P-gamma*grad.reshape(P.shape)\n",
    "            val, grad=g(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma utilisé:0.377431164897\n",
      "valeur optimale: 303938.455544    nombre d'itération: 42\n"
     ]
    }
   ],
   "source": [
    "epsilon=1.\n",
    "cnstLips=rho+np.linalg.norm((Q0.T).dot(Q0))\n",
    "gamma_donne=1./cnstLips\n",
    "print(\"gamma utilisé:\"+str(gamma_donne))\n",
    "val,P_,nombre=gradient(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma_donne,epsilon=epsilon)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raffinements algorimtmiques pour le problème à $Q_{0}$ fixé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "def objectiveGamma(gamma,X0,direction,f):\n",
    "    X=X0 + gamma*direction.reshape(X0.shape)\n",
    "    val, grad_0 = f(X)\n",
    "    \n",
    "    return val\n",
    "\n",
    "\n",
    "def gradient_LinearSearch(g, pointDepart, epsilon):\n",
    "    pointCourant=pointDepart\n",
    "    val, grad=g(pointCourant)\n",
    "    nombre=0\n",
    "    while(True):\n",
    "        if np.linalg.norm(grad)<=epsilon:\n",
    "            return val,pointCourant,nombre\n",
    "        else:\n",
    "            nombre=nombre+1\n",
    "            direction=-grad\n",
    "            gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "            pointCourant=pointCourant+gamma*direction.reshape(pointCourant.shape)\n",
    "            val, grad=g(pointCourant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 303937.249943    nombre d'itération: 11\n"
     ]
    }
   ],
   "source": [
    "val,P_optimal,nombre=gradient_LinearSearch(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction $f$ est une somme de formes quadratiques sur $\\mathbb{R}$ de coefficients de plus haut degré strictement positifs. De plus, la dimension de l'espace de départ est finie. Il est donc justifiable d'avoir recours à l'algorithme de gradient conjugué"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_Conjuge(g, pointDepart, epsilon):\n",
    "    pointCourant=pointDepart\n",
    "    val, grad=g(pointCourant)\n",
    "    direction=-grad\n",
    "    nombre=0\n",
    "    while(True):\n",
    "        if np.linalg.norm(grad)<=epsilon:\n",
    "            return val, pointCourant, nombre\n",
    "        else:\n",
    "            nombre=nombre+1\n",
    "            gamma=optimize.brent(lambda gamma:objectiveGamma(gamma,X0=pointCourant,direction=direction,f=g))\n",
    "            pointCourant=pointCourant+gamma*direction.reshape(pointCourant.shape)\n",
    "            norm1=np.linalg.norm(grad)**2\n",
    "            val, grad=g(pointCourant)\n",
    "            norm2=np.linalg.norm(grad)**2\n",
    "            b=norm2/norm1\n",
    "            direction=-grad+b*direction.reshape(grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valeur optimale: 303936.977522    nombre d'itération: 7\n"
     ]
    }
   ],
   "source": [
    "val,P_optimal,nombre=gradient_Conjuge(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient with constant step size:\n",
      "value_optimal:303938.455544\n",
      "nombreIteration:42\n",
      "run time:4.058878\n",
      "\n",
      "Gradient with line search:\n",
      "value_optimal:303937.249943\n",
      "nombreIteration:11\n",
      "run time:23.115161\n",
      "\n",
      "Gradient conjugé:\n",
      "value_optimal:303936.977522\n",
      "nombreIteration:7\n",
      "run time:12.857316\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.clock()\n",
    "\n",
    "print \"Gradient with constant step size:\"\n",
    "t1=time.clock()\n",
    "val,P_,nombre=gradient(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma_donne,epsilon=epsilon)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n",
    "print(\"\")\n",
    "print \"Gradient with line search:\"\n",
    "t1=time.clock()\n",
    "val,P_optimal,nombre=gradient_LinearSearch(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n",
    "print(\"\")\n",
    "print \"Gradient conjugé:\"\n",
    "t1=time.clock()\n",
    "val,P_optimal,nombre=gradient_Conjuge(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Résolution du problème complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_objective(P, Q, R, mask, rho):\n",
    "    \"\"\"\n",
    "    La fonction objectif du probleme complet.\n",
    "    Prend en entree \n",
    "    P : la variable matricielle de taille C x I\n",
    "    Q : la variable matricielle de taille U x C\n",
    "    R : une matrice de taille U x I\n",
    "    mask : une matrice 0-1 de taille U x I\n",
    "    rho : un reel positif ou nul\n",
    "\n",
    "    Sorties :\n",
    "    val : la valeur de la fonction\n",
    "    grad_P : le gradient par rapport a P\n",
    "    grad_Q : le gradient par rapport a Q\n",
    "    \"\"\"\n",
    "\n",
    "    tmp = (R - Q.dot(P)) * mask\n",
    "\n",
    "    val = np.sum(tmp ** 2)/2. + rho/2. * (np.sum(Q ** 2) + np.sum(P ** 2))\n",
    "\n",
    "    grad_P = rho*P-(Q.T).dot(tmp)\n",
    "\n",
    "    grad_Q = rho*Q-tmp.dot(P.T)\n",
    "\n",
    "    return val, grad_P, grad_Q\n",
    "def total_objective_vectorized(PQvec, R, mask, rho):\n",
    "    \"\"\"\n",
    "    Vectorisation de la fonction precedente de maniere a ne pas\n",
    "    recoder la fonction gradient\n",
    "    \"\"\"\n",
    "\n",
    "    # reconstruction de P et Q\n",
    "    n_items = R.shape[1]\n",
    "    n_users = R.shape[0]\n",
    "    F = PQvec.shape[0] / (n_items + n_users)\n",
    "    Pvec = PQvec[0:n_items*F]\n",
    "    Qvec = PQvec[n_items*F:]\n",
    "    P = np.reshape(Pvec, (F, n_items))\n",
    "    Q = np.reshape(Qvec, (n_users, F))\n",
    "\n",
    "    val, grad_P, grad_Q = total_objective(P, Q, R, mask, rho)\n",
    "    return val, np.concatenate([grad_P.ravel(), grad_Q.ravel()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PQ0=np.concatenate([P0.ravel(), Q0.ravel()])\n",
    "val, PQ, nombre = gradient_LinearSearch(lambda PQvec:total_objective_vectorized(PQvec, R=R, mask=mask, rho=rho),pointDepart=PQ0,epsilon=100)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour $Q_{k-1}$\n",
    " fixé, on a :\n",
    "\n",
    "$$f\\left(P_{k},Q_{k-1}\\right)\\leq f\\left(P_{k-1},Q_{k-1}\\right)$$\n",
    " \n",
    "\n",
    "D'autre part, on a :\n",
    "\n",
    "\\begin{array}{cc}\n",
    " & f\\left(P_{k},Q_{k}\\right)\\leq f\\left(P,Q_{k-1}\\right)\\\\\n",
    "\\Leftrightarrow & f\\left(P_{k},Q_{k}\\right)\\leq f\\left(P_{k},Q_{k-1}\\right)\n",
    "\\end{array}\n",
    " \n",
    "\n",
    "D'après (1) et (2), on a $$f\\left(P_{k},Q_{k}\\right)\\leq f\\left(P_{k-1},Q_{k-1}\\right)$$\n",
    " \n",
    "\n",
    "Ainsi la suite réelle $\\left(u_{k}\\right)_{k}=\\left(f\\left(P_{k},Q_{k}\\right)\\right)_{k}$\n",
    "  est positive et décroissante. Elle est donc convergente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def objective_Q(Q, P0, R, mask, rho):\n",
    "    val, grad_P, grad_Q=total_objective(P=P0,Q=Q,R=R,mask=mask,rho=rho)\n",
    "    return val, grad_Q\n",
    "\n",
    "\n",
    "\n",
    "def gradient_MoindreCarre(P0,Q0,R,mask,rho,epsilon):\n",
    "    nombre=0\n",
    "    val_avant=0\n",
    "    P_courant=P0\n",
    "    Q_courant=Q0\n",
    "\n",
    "    val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon)\n",
    "    nombre=nombre+nbr\n",
    "    P_courant=P_optimal\n",
    "\n",
    "    val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon)\n",
    "    nombre=nombre+nbr\n",
    "    Q_courant=Q_optimal\n",
    "\n",
    "    difference=np.abs(val1-val2)\n",
    "\n",
    "    while(True):\n",
    "        if difference<=epsilon :\n",
    "            return val2,P_courant,Q_courant,nombre\n",
    "        else:\n",
    "            val1,P_optimal,nbr=gradient_LinearSearch(g=lambda P:objective(P,Q0=Q_courant,R=R,mask=mask,rho=rho),pointDepart=P_courant,epsilon=epsilon)\n",
    "            nombre=nombre+nbr\n",
    "            P_courant=P_optimal\n",
    "\n",
    "            val2, Q_optimal,nbr= gradient_LinearSearch(g=lambda Q:objective_Q(Q,P0=P_courant,R=R,mask=mask,rho=rho),pointDepart=Q_courant,epsilon=epsilon)\n",
    "            nombre=nombre+nbr\n",
    "            Q_courant=Q_optimal\n",
    "\n",
    "            difference=np.abs(val1-val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val, P, Q, nombre=gradient_MoindreCarre(P0=P0,Q0=Q0,R=R,mask=mask,rho=rho,epsilon=100)\n",
    "print(\"valeur optimale: \"+str(val)+\"    nombre d'itération: \"+str(nombre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "t0=time.clock()\n",
    "\n",
    "print \"Gradient with constant step size:\"\n",
    "t1=time.clock()\n",
    "val,P_,nombre=gradient(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),P0=P0,gamma=gamma_donne,epsilon=epsilon)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))\n",
    "\n",
    "print(\"\")\n",
    "print \"Gradient with line search:\"\n",
    "t1=time.clock()\n",
    "val,P_optimal,nombre=gradient_LinearSearch(g=lambda P:objective(P,Q0=Q0,R=R,mask=mask,rho=rho),pointDepart=P0,epsilon=epsilon)\n",
    "t2=time.clock()\n",
    "duree=t2-t1\n",
    "print(\"value_optimal:\"+str(val))\n",
    "print(\"nombreIteration:\"+str(nombre))\n",
    "print(\"run time:\"+str(duree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
